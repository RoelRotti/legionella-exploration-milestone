{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'example.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m     31\u001b[0m pdf_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexample.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Replace with your PDF file\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m tables \u001b[38;5;241m=\u001b[39m \u001b[43mextract_tables_from_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Save the first table to a CSV file (optional)\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tables:\n",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m, in \u001b[0;36mextract_tables_from_pdf\u001b[0;34m(pdf_path)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_tables_from_pdf\u001b[39m(pdf_path):\n\u001b[1;32m      5\u001b[0m     tables \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mpdfplumber\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m pdf:\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m page_number, page \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(pdf\u001b[38;5;241m.\u001b[39mpages, start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      8\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing page \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Odyss/Legionella/venv/lib/python3.11/site-packages/pdfplumber/pdf.py:92\u001b[0m, in \u001b[0;36mPDF.open\u001b[0;34m(cls, path_or_fp, pages, laparams, password, strict_metadata, unicode_norm, repair, gs_path, repair_setting)\u001b[0m\n\u001b[1;32m     90\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_fp, (\u001b[38;5;28mstr\u001b[39m, pathlib\u001b[38;5;241m.\u001b[39mPath)):\n\u001b[0;32m---> 92\u001b[0m     stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath_or_fp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     stream_is_external \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     94\u001b[0m     path \u001b[38;5;241m=\u001b[39m pathlib\u001b[38;5;241m.\u001b[39mPath(path_or_fp)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'example.pdf'"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "\n",
    "def extract_tables_from_pdf(pdf_path):\n",
    "    tables = []\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page_number, page in enumerate(pdf.pages, start=1):\n",
    "            print(f\"Processing page {page_number}...\")\n",
    "            # Extract tables from the page\n",
    "            page_tables = page.extract_tables()\n",
    "            for i, table in enumerate(page_tables):\n",
    "                print(f\"Extracted table {i + 1} from page {page_number}\")\n",
    "                # Convert the table into a Pandas DataFrame\n",
    "                df = pd.DataFrame(table)\n",
    "                tables.append(df)\n",
    "                print(df.head())  # Display the first few rows of the table\n",
    "    return tables\n",
    "\n",
    "# Example usage\n",
    "pdf_path = \"example.pdf\"  # Replace with your PDF file\n",
    "tables = extract_tables_from_pdf(pdf_path)\n",
    "\n",
    "# Save the first table to a CSV file (optional)\n",
    "if tables:\n",
    "    tables[0].to_csv(\"extracted_table.csv\", index=False)\n",
    "    print(\"First table saved to 'extracted_table.csv'\")\n",
    "else:\n",
    "    print(\"No tables found in the PDF.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected Tables:\n",
      "\n",
      "Table 1:\n",
      "Dimensions: 21 rows x 2 columns\n",
      "Management Details\t\n",
      "This risk assessment has been conducted on behalf of:\tT & D Barrs Plumbing & Heating Ltd\n",
      "\tUnit 7 Thundridge Business Park Thundridge Nr Ware Hertfordshire\n",
      "\tSG12 0SS\n",
      "\t\n",
      "Site Details\t\n",
      "This risk assessment relates to the hot and cold water services\tBarnehurst Junior School Barnehurst Close\n",
      "\tErith\n",
      "for the following site:\tDA8 3NL\n",
      "Site Contact\tMr L Polden\n",
      "Responsible Person\tMr L Polden\n",
      "Date of Survey\t29/10/2022\n",
      "Surveyor(s)\tChris Helmore, Jamie Helmore\n",
      "Survey Review Date\t29/10/2024\n",
      "\t\n",
      "Administrative Details\t\n",
      "Job Reference\t9484630\n",
      "Risk Assessment Produced by\tChris Helmore\n",
      "Helmore Water Site Contacts\tlan Helmore - 07778 381851\n",
      "\tChris Helmore - 07540 403870\n",
      "\tJamie Helmore - 07810 501335 Head Office - 01462 895588\n",
      "\n",
      "Table 2:\n",
      "Dimensions: 7 rows x 2 columns\n",
      "General Building information\t\n",
      "Site name:\tBarnehurst Junior School\n",
      "Building Use:\tSchool\n",
      "Number of Floors:\t2\n",
      "Age of Building\t1920s\n",
      "Building Occupancy\tOccupied on a daily basis\n",
      "Susceptible Individuals\tThis Premises is usually occupied by a mixture of young children and teachers. This means that there is a mixture of low risk and moderate risk occupants. Other factors such as smoking may increase the risk of individuals.\n",
      "\n",
      "Table 3:\n",
      "Dimensions: 7 rows x 2 columns\n",
      "Building Water Services Information\t\n",
      "Water Source\tTown Main\n",
      "Drinking Water\tMains Fed\n",
      "Cold Water\tMains Fed\n",
      "Hot Water\tUnvented Cylinders\n",
      "Spray Systems Present\tYes\n",
      "Evaporative Systems Present\tNo\n",
      "\n",
      "Table 4:\n",
      "Dimensions: 3 rows x 4 columns\n",
      "\tLow Risk\tMedium Risk\tHigh Risk\n",
      "\t3-12\t13-36\t36-88\n",
      "Score\t\t18\t\n",
      "\n",
      "Table 5:\n",
      "Dimensions: 6 rows x 2 columns\n",
      "Risk ID: 1\t\n",
      "Asset Type\tAuto-Pressurisation Unit\n",
      "Location\tPlant Room\n",
      "Risk Description\tAPU cold mains water feed is an effective dead leg, double check valve is not fitted far enough back close to tee branch.\n",
      "Risk Factor\tHigh\n",
      "Photographic Evidence\t\n",
      "\n",
      "Table 6:\n",
      "Dimensions: 2 rows x 6 columns\n",
      "Works Approved?\tAction Completed?\tContractor Name\tDate Completed\tSenior Engineers Signature\tResponsible Persons Signature\n",
      "\t\t\t\t\t\n",
      "\n",
      "Table 7:\n",
      "Dimensions: 4 rows x 2 columns\n",
      "Asset Type\tOutlet\n",
      "Location\tSite-wide\n",
      "Risk Description\tVarious outlets are scaled which can allow bacteria to grow\n",
      "Risk Factor\tHigh\n",
      "\n",
      "Table 8:\n",
      "Dimensions: 2 rows x 6 columns\n",
      "Works Approved?\tAction Completed?\tContractor Name\tDate Completed\tSenior Engineers Signature\tResponsible Persons Signature\n",
      "\t\t\t\t\t\n",
      "\n",
      "Table 9:\n",
      "Dimensions: 6 rows x 2 columns\n",
      "Risk ID: 3\t\n",
      "Asset Type\tMains Pipework\n",
      "Location\tGirls toilets by cooking\n",
      "Risk Description\tDead leg of pipework or potential low use feed\n",
      "Risk Factor\tHigh\n",
      "Photographic Evidence\t\n",
      "\n",
      "Table 10:\n",
      "Dimensions: 2 rows x 6 columns\n",
      "Works Approved?\tAction Completed?\tContractor Name\tDate Completed\tSenior Engineers Signature\tResponsible Persons Signature\n",
      "\t\t\t\t\t\n",
      "\n",
      "Table 11:\n",
      "Dimensions: 4 rows x 2 columns\n",
      "Risk ID: 4\t\n",
      "Asset Type\tExternal Tap\n",
      "Location\tExternal Wall of Gandhi Mobile Class\n",
      "Risk Description\tLow use outlet\n",
      "\n",
      "Table 12:\n",
      "Dimensions: 2 rows x 6 columns\n",
      "Works Approved?\tAction Completed?\tContractor Name\tDate Completed\tSenior Engineers Signature\tResponsible Persons Signature\n",
      "\t\t\t\t\t\n",
      "\n",
      "Table 13:\n",
      "Dimensions: 2 rows x 6 columns\n",
      "Works Approved?\tAction Completed?\tContractor Name\tDate Completed\tSenior Engineers Signature\tResponsible Persons Signature\n",
      "\t\t\t\t\t\n",
      "\n",
      "Table 14:\n",
      "Dimensions: 4 rows x 2 columns\n",
      "Risk ID: 6\t\n",
      "Asset Type\tExternal Tap\n",
      "Location\tExternal Wall of Staff Room Building\n",
      "Risk Description\tLow use outlet\n",
      "\n",
      "Table 15:\n",
      "Dimensions: 2 rows x 6 columns\n",
      "Works Approved?\tAction Completed?\tContractor Name\tDate Completed\tSenior Engineers Signature\tResponsible Persons Signature\n",
      "\t\t\t\t\t\n",
      "\n",
      "Table 16:\n",
      "Dimensions: 6 rows x 2 columns\n",
      "Risk ID: 7\t\n",
      "Asset Type\tElectric Handwash Unit\n",
      "Location\tKitchen\n",
      "Risk Description\tElectric hand wash possible low use outlet\n",
      "Risk Factor\tHigh\n",
      "Photographic Evidence\t\n",
      "\n",
      "Table 17:\n",
      "Dimensions: 2 rows x 6 columns\n",
      "Works Approved?\tAction Completed?\tContractor Name\tDate Completed\tSenior Engineers Signature\tResponsible Persons Signature\n",
      "\t\t\t\t\t\n",
      "\n",
      "Table 18:\n",
      "Dimensions: 6 rows x 2 columns\n",
      "Risk ID: 8\t\n",
      "Asset Type\tMains Pipework\n",
      "Location\tSite wide\n",
      "Risk Description\tUninsulated pipework.\n",
      "Risk Factor\tMedium\n",
      "Photographic Evidence\t\n",
      "\n",
      "Table 19:\n",
      "Dimensions: 2 rows x 6 columns\n",
      "Works Approved?\tAction Completed?\tContractor Name\tDate Completed\tSenior Engineers Signature\tResponsible Persons Signature\n",
      "\t\t\t\t\t\n",
      "\n",
      "Table 20:\n",
      "Dimensions: 5 rows x 2 columns\n",
      "Risk ID: 9\t\n",
      "Asset Type\tMains Pipework\n",
      "Location\tKitchen\n",
      "Risk Description\tPiped in a way that causes a dead leg (possibly a previous return that hasn't been taken out\n",
      "Risk Factor\tHigh\n",
      "\n",
      "Table 21:\n",
      "Dimensions: 2 rows x 6 columns\n",
      "Works Approved?\tAction Completed?\tContractor Name\tDate Completed\tSenior Engineers Signature\tResponsible Persons Signature\n",
      "\t\t\t\t\t\n",
      "\n",
      "Table 22:\n",
      "Dimensions: 9 rows x 2 columns\n",
      "Risk ID: 10\t\n",
      "Asset Type\tOutlet\n",
      "Location\tKitchen\n",
      "Risk Description\tlow use outlet\n",
      "Risk Factor\tHigh\n",
      "Photographic Evidence\t\n",
      "\tCaution Hot surface\n",
      "Recommendations\t\n",
      "If this does not get used regularly then flush once per week.\t\n",
      "\n",
      "Table 23:\n",
      "Dimensions: 2 rows x 6 columns\n",
      "Works Approved?\tAction Completed?\tContractor Name\tDate Completed\tSenior Engineers Signature\tResponsible Persons Signature\n",
      "\t\t\t\t\t\n",
      "\n",
      "Table 24:\n",
      "Dimensions: 5 rows x 2 columns\n",
      "Risk ID: 11\t\n",
      "Asset Type\tExternal Outlet\n",
      "Location\tExternal Wall of Kitchen Building\n",
      "Risk Description\tPossible low use outlet with a hose laying on the floor\n",
      "Risk Factor\tHigh\n",
      "\n",
      "Table 25:\n",
      "Dimensions: 2 rows x 6 columns\n",
      "Works Approved?\tAction Completed?\tContractor Name\tDate Completed\tSenior Engineers Signature\tResponsible Persons Signature\n",
      "\t\t\t\t\t\n",
      "\n",
      "Table 26:\n",
      "Dimensions: 2 rows x 3 columns\n",
      "Low Risk\tMedium Risk\tHigh Risk\n",
      "3-12\t13-36\t36-88\n",
      "\n",
      "Table 27:\n",
      "Dimensions: 3 rows x 3 columns\n",
      "Isolation Valve\tX\n",
      ":selected:\tPressure Vessel :unselected:\n",
      "Drain Cock\tX\n",
      ":selected:\tPump :selected:\n",
      "RPZ Valve\t:unselected:\t\n",
      "\n",
      "Table 28:\n",
      "Dimensions: 14 rows x 3 columns\n",
      "Asset ID\tDescription\tLocation\n",
      "001\tUnvented Water Heater 01\tPlant Room\n",
      "002\tUnvented Water Heater 02\tPlant Room\n",
      "003\tUnvented Water Heater 03\tKitchen\n",
      "004\tUnvented Water Heater 04\tKitchen\n",
      "005\tUnvented Water Heater 05\tMobile Classroom\n",
      "006\tElectric Handwash 01\tKitchen\n",
      "007\tAuto-Pressurisation Unit 01\tPlant Room\n",
      "008\tPressure Vessel 01\tPlant Room\n",
      "009\tPressure Vessel 02\tPlant Room\n",
      "010\tPressure Vessel 03\tKitchen\n",
      "011\tPressure Vessel 04\tMobile Classroom\n",
      "012\tReturn Pump 01\tPlant Room\n",
      "013\tTea Point 01\tStaff Room\n",
      "\n",
      "Table 29:\n",
      "Dimensions: 15 rows x 4 columns\n",
      "\tYes\tNo\tComments\n",
      "Is there a Risk Assessment?\t✓\n",
      ":selected:\t:unselected:\t\n",
      "Risk Systems on site?\t✓\n",
      ":selected:\t:unselected:\t\n",
      "Particularly susceptible occupants present?\t:unselected:\t✓\n",
      ":selected:\t\n",
      "Is there an up to date logbook\t✓\n",
      ":selected:\t:unselected:\t\n",
      "Is there system of control?\t✓\n",
      ":selected:\t:unselected:\t\n",
      "Is the purpose of the SOC detailed\t✓\n",
      ":selected:\t:unselected:\t\n",
      "Responsible persons detailed\t✓\n",
      ":selected:\t:unselected:\t\n",
      "Reporting Structure\t✓\n",
      ":selected:\t:unselected:\t\n",
      "Lines of communication\t✓\n",
      ":selected:\t:unselected:\t\n",
      "Schematics of plant layout present and valid\t✓\n",
      ":selected:\t:unselected:\t\n",
      "Is there a regime of tests? (e.g. temps)\t✓\n",
      ":selected:\t:unselected:\t\n",
      "Training records present\t✓\n",
      ":selected:\t:unselected:\t\n",
      "Action plan in the event of outbreak detailed at the site\t✓\n",
      ":selected:\t:unselected:\t\n",
      "Description of testing regime\t✓\n",
      ":selected:\t:unselected:\t\n",
      "\n",
      "Table 30:\n",
      "Dimensions: 15 rows x 4 columns\n",
      "\tYes\tNo\tComments\n",
      "Flushing of water systems\t\t\t\n",
      "Weekly low use outlets flushed?\t✓\n",
      ":selected:\t:unselected:\t\n",
      "Expansion vessels flushed (monthly-six monthly?)\t✓\n",
      ":selected:\t:unselected:\t\n",
      "Hot water systems\t\t\t\n",
      "Monthly calorifier readings?\t✓\n",
      ":selected:\t:unselected:\t\n",
      "Monthly tap temperatures?\t✓\n",
      ":selected:\t:unselected:\t\n",
      "Annual key tap temperatures?\t✓\n",
      ":selected:\t:unselected:\t\n",
      "Six monthly / monthly EWH outlet testing?\t✓\n",
      ":selected:\t:unselected:\t\n",
      "Six month failsafe checks?\t✓\n",
      ":selected:\t:unselected:\t\n",
      "Cold water systems\t\t\t\n",
      "DCW storage tank temperatures monitored?\t:unselected:\t:unselected:\tN/A\n",
      "Annual inspection / disinfection?\t:unselected:\t:unselected:\tN/A\n",
      "Monthly tap temperatures?\t:unselected:\t:unselected:\tN/A\n",
      "Annual key tap temperatures?\t:unselected:\t:unselected:\tN/A\n",
      "Analyzing Page 1 for potential tables...\n",
      "Analyzing Page 2 for potential tables...\n",
      "Analyzing Page 3 for potential tables...\n",
      "Analyzing Page 4 for potential tables...\n",
      "Analyzing Page 5 for potential tables...\n",
      "Analyzing Page 6 for potential tables...\n",
      "Analyzing Page 7 for potential tables...\n",
      "Analyzing Page 8 for potential tables...\n",
      "Analyzing Page 9 for potential tables...\n",
      "Analyzing Page 10 for potential tables...\n",
      "Analyzing Page 11 for potential tables...\n",
      "Analyzing Page 12 for potential tables...\n",
      "Analyzing Page 13 for potential tables...\n",
      "Analyzing Page 14 for potential tables...\n",
      "Analyzing Page 15 for potential tables...\n",
      "Analyzing Page 16 for potential tables...\n",
      "Analyzing Page 17 for potential tables...\n",
      "Analyzing Page 18 for potential tables...\n",
      "Analyzing Page 19 for potential tables...\n",
      "Analyzing Page 20 for potential tables...\n",
      "Analyzing Page 21 for potential tables...\n",
      "Analyzing Page 22 for potential tables...\n",
      "Analyzing Page 23 for potential tables...\n",
      "Analyzing Page 24 for potential tables...\n",
      "Analyzing Page 25 for potential tables...\n",
      "Analyzing Page 26 for potential tables...\n",
      "Analyzing Page 27 for potential tables...\n",
      "Analyzing Page 28 for potential tables...\n",
      "Analyzing Page 29 for potential tables...\n",
      "Analyzing Page 30 for potential tables...\n",
      "Analyzing Page 31 for potential tables...\n",
      "Analyzing Page 32 for potential tables...\n",
      "Analyzing Page 33 for potential tables...\n",
      "Analyzing Page 34 for potential tables...\n",
      "Analyzing Page 35 for potential tables...\n",
      "Analyzing Page 36 for potential tables...\n",
      "Analyzing Page 37 for potential tables...\n",
      "Analyzing Page 38 for potential tables...\n",
      "Analyzing Page 39 for potential tables...\n",
      "Analyzing Page 40 for potential tables...\n",
      "Analyzing Page 41 for potential tables...\n",
      "Analyzing Page 42 for potential tables...\n",
      "Analyzing Page 43 for potential tables...\n",
      "Analyzing Page 44 for potential tables...\n",
      "Analyzing Page 45 for potential tables...\n",
      "Analyzing Page 46 for potential tables...\n",
      "Analyzing Page 47 for potential tables...\n",
      "Analyzing Page 48 for potential tables...\n",
      "\n",
      "No potential missing tables found.\n"
     ]
    }
   ],
   "source": [
    "showConfidence = True\n",
    "\n",
    "from azure.ai.formrecognizer import DocumentAnalysisClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "# Azure credentials\n",
    "endpoint = \"https://westeurope.api.cognitive.microsoft.com/\"\n",
    "key = \"7614bee5e8c042439d637938ae2bb3af\"\n",
    "\n",
    "# Initialize the Document Analysis Client\n",
    "document_analysis_client = DocumentAnalysisClient(\n",
    "    endpoint=endpoint, credential=AzureKeyCredential(key)\n",
    ")\n",
    "\n",
    "# Path to your PDF document\n",
    "document_path = \"9484630 Barnehurst Junior School Risk Assessment 22.pdf\"\n",
    "\n",
    "# Read the document content\n",
    "with open(document_path, \"rb\") as f:\n",
    "    document = f.read()\n",
    "\n",
    "# Analyze the document using the prebuilt-document model to detect explicit tables\n",
    "poller = document_analysis_client.begin_analyze_document(\n",
    "    model_id=\"prebuilt-document\", document=document\n",
    ")\n",
    "result = poller.result()\n",
    "\n",
    "# Print detected tables\n",
    "if result.tables:\n",
    "    print(\"\\nDetected Tables:\")\n",
    "    for idx, table in enumerate(result.tables):\n",
    "        print(f\"\\nTable {idx + 1}:\")\n",
    "        print(f\"Dimensions: {table.row_count} rows x {table.column_count} columns\")\n",
    "        \n",
    "        # Initialize a 2D grid to store table data\n",
    "        table_data = [[\"\" for _ in range(table.column_count)] for _ in range(table.row_count)]\n",
    "        \n",
    "        # Populate the grid with cell content\n",
    "        for cell in table.cells:\n",
    "            table_data[cell.row_index][cell.column_index] = cell.content\n",
    "        \n",
    "        # Print the table content row by row\n",
    "        for row in table_data:\n",
    "            print(\"\\t\".join(row))\n",
    "else:\n",
    "    print(\"No tables detected in the document.\")\n",
    "\n",
    "\n",
    "###############\n",
    "\n",
    "# Analyze the document using layout mode for more granular structure\n",
    "poller = document_analysis_client.begin_analyze_document(\n",
    "    model_id=\"prebuilt-layout\", document=document\n",
    ")\n",
    "layout_result = poller.result()\n",
    "\n",
    "# Gather detected table regions\n",
    "detected_table_regions = []\n",
    "for table in result.tables:\n",
    "    for region in table.bounding_regions:\n",
    "        detected_table_regions.append(region)\n",
    "\n",
    "# Analyze lines to identify high-density regions (potential missing tables)\n",
    "potential_table_regions = []\n",
    "\n",
    "for page in layout_result.pages:\n",
    "    print(f\"Analyzing Page {page.page_number} for potential tables...\")\n",
    "    line_density_threshold = 5  # Number of lines per region to consider as a table\n",
    "    line_groups = {}\n",
    "\n",
    "    # Group lines by proximity based on spans\n",
    "    for line in page.lines:\n",
    "        # Use the span's offset as a unique identifier\n",
    "        line_span = line.spans[0]  # Assuming one span per line\n",
    "        span_start = line_span.offset\n",
    "        span_end = span_start + line_span.length\n",
    "\n",
    "        # Group lines based on vertical proximity (using span offsets)\n",
    "        found_group = False\n",
    "        for group_key in line_groups:\n",
    "            group_start, group_end = group_key\n",
    "            if abs(group_start - span_start) < 10 or abs(group_end - span_end) < 10:\n",
    "                line_groups[group_key].append(line)\n",
    "                found_group = True\n",
    "                break\n",
    "\n",
    "        if not found_group:\n",
    "            line_groups[(span_start, span_end)] = [line]\n",
    "\n",
    "    # Check each group for line density\n",
    "    for group_key, lines in line_groups.items():\n",
    "        if len(lines) > line_density_threshold:\n",
    "            potential_table_regions.append((page.page_number, group_key, lines))\n",
    "\n",
    "# Compare detected tables with potential table regions\n",
    "missing_tables = []\n",
    "for page_number, group_key, lines in potential_table_regions:\n",
    "    span_start, span_end = group_key\n",
    "    is_detected = False\n",
    "    for detected_region in detected_table_regions:\n",
    "        if (\n",
    "            detected_region.page_number == page_number\n",
    "            and detected_region.bounding_box[0][1] <= span_start\n",
    "            and detected_region.bounding_box[2][1] >= span_end\n",
    "        ):\n",
    "            is_detected = True\n",
    "            break\n",
    "\n",
    "    if not is_detected:\n",
    "        missing_tables.append((page_number, span_start, span_end, lines))\n",
    "\n",
    "# Output missing tables\n",
    "if missing_tables:\n",
    "    print(\"\\nPotential missing tables identified:\")\n",
    "    for page_number, span_start, span_end, lines in missing_tables:\n",
    "        print(f\"Page {page_number}, Region: {span_start} - {span_end}\")\n",
    "        for line in lines:\n",
    "            print(f\"  Line: {line.content}\")\n",
    "else:\n",
    "    print(\"\\nNo potential missing tables found.\")\n",
    "\n",
    "\n",
    "\n",
    "################\n",
    "# # Analyze the document using the prebuilt model\n",
    "# poller = document_analysis_client.begin_analyze_document(\n",
    "#     model_id=\"prebuilt-layout\", document=document\n",
    "# )\n",
    "# result = poller.result()\n",
    "\n",
    "# low_confidence_flag = False\n",
    "# low_confidence_threshold = 0.5  # Adjust as needed\n",
    "\n",
    "# # Iterate through detected tables\n",
    "# for table_idx, table in enumerate(result.tables):\n",
    "#     print(f\"\\nChecking Table {table_idx + 1}:\")\n",
    "#     for cell in table.cells:\n",
    "#         # Collect confidences of words within the cell\n",
    "#         cell_confidences = []\n",
    "\n",
    "#         if cell.spans:\n",
    "#             for span in cell.spans:\n",
    "#                 span_start = span.offset\n",
    "#                 span_end = span.offset + span.length\n",
    "#                 for page in result.pages:\n",
    "#                     for word in page.words:\n",
    "#                         word_start = word.span.offset\n",
    "#                         word_end = word.span.offset + word.span.length\n",
    "#                         if word_start >= span_start and word_end <= span_end:\n",
    "#                             cell_confidences.append(word.confidence)\n",
    "\n",
    "#         # Calculate the average confidence for the cell\n",
    "#         if cell_confidences:\n",
    "#             avg_confidence = sum(cell_confidences) / len(cell_confidences)\n",
    "#         else:\n",
    "#             avg_confidence = None\n",
    "\n",
    "#         # Flag if confidence is below the threshold\n",
    "#         if avg_confidence is not None and avg_confidence < low_confidence_threshold:\n",
    "#             low_confidence_flag = True\n",
    "#             print(\n",
    "#                 f\"Low-confidence cell detected in Table {table_idx + 1} \"\n",
    "#                 f\"at Row {cell.row_index + 1}, Column {cell.column_index + 1} \"\n",
    "#                 f\"(Conf: {avg_confidence:.2f}): {cell.content}\"\n",
    "#             )\n",
    "\n",
    "# if low_confidence_flag:\n",
    "#     print(\"\\nWarning: Some tables in the document contain low-confidence cells.\")\n",
    "# else:\n",
    "#     print(\"\\nAll detected tables have acceptable confidence levels.\")\n",
    "\n",
    "##########\n",
    "\n",
    "# # Iterate through tables and extract cell data with confidence scores\n",
    "# for idx, table in enumerate(result.tables):\n",
    "#     print(f\"\\nTable {idx + 1}:\")\n",
    "\n",
    "#     # Get the number of rows and columns\n",
    "#     row_count = table.row_count\n",
    "#     column_count = table.column_count\n",
    "#     print(f\"Dimensions: {row_count} rows x {column_count} columns\")\n",
    "\n",
    "#     # Create a 2D list to hold cell contents and confidences\n",
    "#     cells = [[\"\" for _ in range(column_count)] for _ in range(row_count)]\n",
    "#     confidences = [[None for _ in range(column_count)] for _ in range(row_count)]\n",
    "\n",
    "#     # Populate the cells and confidences\n",
    "#     for cell in table.cells:\n",
    "#         row = cell.row_index\n",
    "#         column = cell.column_index\n",
    "#         cells[row][column] = cell.content\n",
    "\n",
    "#         # Initialize a list to hold confidences of words in the cell\n",
    "#         cell_confidences = []\n",
    "\n",
    "#         # Access the elements (words) within the cell\n",
    "#         if cell.spans:\n",
    "#             for span in cell.spans:\n",
    "#                 # Get the start and end offsets of the span\n",
    "#                 span_start = span.offset\n",
    "#                 span_end = span.offset + span.length\n",
    "\n",
    "#                 # Find words within the span\n",
    "#                 for page in result.pages:\n",
    "#                     for word in page.words:\n",
    "#                         word_start = word.span.offset\n",
    "#                         word_end = word.span.offset + word.span.length\n",
    "#                         if (word_start >= span_start) and (word_end <= span_end):\n",
    "#                             cell_confidences.append(word.confidence)\n",
    "#         # Calculate average confidence\n",
    "#         if cell_confidences:\n",
    "#             avg_confidence = sum(cell_confidences) / len(cell_confidences)\n",
    "#         else:\n",
    "#             avg_confidence = None\n",
    "\n",
    "#         confidences[row][column] = avg_confidence\n",
    "\n",
    "\n",
    "#     # Print the table with cell contents and confidence scores\n",
    "#     for row_idx in range(row_count):\n",
    "#         row_cells = cells[row_idx]\n",
    "#         row_confidences = confidences[row_idx]\n",
    "#         row_output = \"\"\n",
    "#         for col_idx in range(column_count):\n",
    "#             cell_text = row_cells[col_idx]\n",
    "#             confidence = row_confidences[col_idx]\n",
    "#             if confidence is not None:\n",
    "#                 if showConfidence:\n",
    "#                     row_output += f\"[{cell_text} (Conf: {confidence:.2f})]\\t\"\n",
    "#                 else:\n",
    "#                     row_output += f\"[{cell_text}]\\t\"\n",
    "#             else:\n",
    "#                 if showConfidence:\n",
    "#                     row_output += f\"[{cell_text} (Conf: N/A)]\\t\"\n",
    "#                 else:\n",
    "#                     row_output += f\"[{cell_text}]\\t\"\n",
    "#         print(row_output)\n",
    "\n",
    "    \n",
    "# print(\"--------------------------------\")\n",
    "\n",
    "# low_confidence_flag = False\n",
    "\n",
    "# for page in result.pages:\n",
    "#     for word in page.words:\n",
    "#         if word.confidence < 0.5:  # Adjust threshold as needed\n",
    "#             low_confidence_flag = True\n",
    "#             print(f\"Low-confidence word detected: {word.content} (Conf: {word.confidence:.2f})\")\n",
    "\n",
    "# if low_confidence_flag:\n",
    "#     print(\"Warning: Some areas in the document have low confidence.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-10 14:27:23.492 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-10 14:27:23.806 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /Users/roelrotteveel/Documents/Odyss/Legionella/venv/lib/python3.11/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2024-12-10 14:27:23.807 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-10 14:27:23.818 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-10 14:27:23.819 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-10 14:27:23.819 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-10 14:27:23.826 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-10 14:27:23.828 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import io\n",
    "from PIL import Image\n",
    "import streamlit as st\n",
    "\n",
    "def upload_to_s3(uploaded_file, bucket):\n",
    "    \"\"\"\n",
    "    Upload a local file to S3\n",
    "    \n",
    "    Args:\n",
    "        uploaded_file: File uploaded by user\n",
    "        bucket (str): S3 bucket name\n",
    "    \n",
    "    Returns:\n",
    "        str: S3 object key\n",
    "    \"\"\"\n",
    "    # s3_client = boto3.client('s3')\n",
    "\n",
    "    s3_client = boto3.client(\n",
    "        's3',\n",
    "        aws_access_key_id='AKIAYXWBNYPDQSE47NE7',\n",
    "        aws_secret_access_key='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',\n",
    "        region_name='us-east-1'\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Generate a unique filename\n",
    "    filename = f\"uploads/{uploaded_file.name}\"\n",
    "    \n",
    "    # Upload file to S3\n",
    "    s3_client.upload_fileobj(uploaded_file, bucket, filename)\n",
    "    \n",
    "    return filename\n",
    "\n",
    "def extract_tables_from_pdf(bucket, document):\n",
    "    \"\"\"\n",
    "    Extract tables from a PDF document stored in an S3 bucket\n",
    "    \n",
    "    Args:\n",
    "        bucket (str): S3 bucket name\n",
    "        document (str): PDF document path in S3\n",
    "    \n",
    "    Returns:\n",
    "        list: Extracted tables\n",
    "    \"\"\"\n",
    "    # Create Textract client\n",
    "    textract = boto3.client('textract')\n",
    "    \n",
    "    try:\n",
    "        # Analyze document for tables\n",
    "        response = textract.analyze_document(\n",
    "            Document={\n",
    "                'S3Object': {\n",
    "                    'Bucket': bucket,\n",
    "                    'Name': document\n",
    "                }\n",
    "            },\n",
    "            FeatureTypes=['TABLES']\n",
    "        )\n",
    "        \n",
    "        # Process and extract tables\n",
    "        tables = []\n",
    "        for page in response['Blocks']:\n",
    "            if page['BlockType'] == 'TABLE':\n",
    "                current_table = []\n",
    "                \n",
    "                # Get table cells\n",
    "                table_cells = [cell for cell in response['Blocks'] \n",
    "                               if cell['BlockType'] == 'CELL' and cell['TableIndex'] == page['TableIndex']]\n",
    "                \n",
    "                # Sort cells by row and column\n",
    "                table_cells.sort(key=lambda x: (x['RowIndex'], x['ColumnIndex']))\n",
    "                \n",
    "                # Track current row\n",
    "                current_row = []\n",
    "                prev_row_index = 1\n",
    "                \n",
    "                for cell in table_cells:\n",
    "                    # Extract cell text\n",
    "                    cell_text = ''\n",
    "                    for relationship in cell.get('Relationships', []):\n",
    "                        if relationship['Type'] == 'CHILD':\n",
    "                            for child_id in relationship['Ids']:\n",
    "                                for word in response['Blocks']:\n",
    "                                    if word['Id'] == child_id and word['BlockType'] == 'WORD':\n",
    "                                        cell_text += word['Text'] + ' '\n",
    "                    cell_text = cell_text.strip()\n",
    "                    \n",
    "                    # Handle row changes\n",
    "                    if cell['RowIndex'] != prev_row_index:\n",
    "                        if current_row:\n",
    "                            tables.append(current_row)\n",
    "                        current_row = []\n",
    "                        prev_row_index = cell['RowIndex']\n",
    "                    \n",
    "                    current_row.append(cell_text)\n",
    "                \n",
    "                # Add last row\n",
    "                if current_row:\n",
    "                    tables.append(current_row)\n",
    "        \n",
    "        return tables\n",
    "    \n",
    "    except Exception as e:\n",
    "        st.error(f\"Error extracting tables: {e}\")\n",
    "        return []\n",
    "\n",
    "def print_tables(tables):\n",
    "    \"\"\"\n",
    "    Print extracted tables in a readable format\n",
    "    \n",
    "    Args:\n",
    "        tables (list): List of tables to print\n",
    "    \"\"\"\n",
    "    if not tables:\n",
    "        st.warning(\"No tables found.\")\n",
    "        return\n",
    "    \n",
    "    st.write(f\"Total Tables Found: {len(tables)}\")\n",
    "    \n",
    "    for i, table in enumerate(tables, 1):\n",
    "        st.write(f\"\\n### Table {i}\")\n",
    "        \n",
    "        # Display table using Streamlit\n",
    "        st.dataframe(table)\n",
    "\n",
    "def main():\n",
    "    st.title(\"Amazon Textract PDF Table Extractor\")\n",
    "    \n",
    "    # AWS Configuration\n",
    "    BUCKET_NAME = st.secrets[\"AWS_S3_BUCKET\"]\n",
    "    \n",
    "    # File uploader\n",
    "    uploaded_file = st.file_uploader(\"Choose a PDF file\", type=\"pdf\")\n",
    "    \n",
    "    if uploaded_file is not None:\n",
    "        # Upload file to S3\n",
    "        try:\n",
    "            st.info(\"Uploading file to S3...\")\n",
    "            s3_filename = upload_to_s3(uploaded_file, BUCKET_NAME)\n",
    "            st.success(\"File uploaded successfully!\")\n",
    "            \n",
    "            # Extract tables\n",
    "            st.info(\"Extracting tables...\")\n",
    "            tables = extract_tables_from_pdf(BUCKET_NAME, s3_filename)\n",
    "            \n",
    "            # Print tables\n",
    "            print_tables(tables)\n",
    "        \n",
    "        except Exception as e:\n",
    "            st.error(f\"An error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
